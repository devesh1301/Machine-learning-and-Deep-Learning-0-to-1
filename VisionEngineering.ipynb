{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#importing Keras, Library for deep learning  \n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten \n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D \n",
    "from keras.utils import np_utils \n",
    "from keras.preprocessing.image import  img_to_array \n",
    "from keras import backend as K \n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theano.config.optimizer=\"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumara213\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fabric_moderate_001_new.jpg', 'fabric_moderate_002_new.jpg', 'fabric_moderate_003_new.jpg', 'fabric_moderate_004_new.jpg', 'fabric_moderate_005_new.jpg', 'fabric_moderate_006_new.jpg', 'fabric_moderate_007_new.jpg', 'fabric_moderate_008_new.jpg', 'fabric_moderate_009_new.jpg', 'fabric_moderate_010_new.jpg', 'fabric_moderate_011_new.jpg', 'fabric_moderate_012_new.jpg', 'fabric_moderate_013_new.jpg', 'fabric_moderate_014_new.jpg', 'fabric_moderate_015_new.jpg', 'fabric_moderate_016_new.jpg', 'fabric_moderate_017_new.jpg', 'fabric_moderate_018_new.jpg', 'fabric_moderate_019_new.jpg', 'fabric_moderate_020_new.jpg', 'fabric_moderate_021_new.jpg', 'fabric_moderate_022_new.jpg', 'fabric_moderate_023_new.jpg', 'fabric_moderate_024_new.jpg', 'fabric_moderate_025_new.jpg', 'fabric_moderate_026_new.jpg', 'fabric_moderate_027_new.jpg', 'fabric_moderate_028_new.jpg', 'fabric_moderate_029_new.jpg', 'fabric_moderate_030_new.jpg', 'fabric_moderate_031_new.jpg', 'fabric_moderate_032_new.jpg', 'fabric_moderate_033_new.jpg', 'fabric_moderate_034_new.jpg', 'fabric_moderate_035_new.jpg', 'fabric_moderate_036_new.jpg', 'fabric_moderate_037_new.jpg', 'fabric_moderate_038_new.jpg', 'fabric_moderate_039_new.jpg', 'fabric_moderate_040_new.jpg', 'fabric_moderate_041_new.jpg', 'fabric_moderate_042_new.jpg', 'fabric_moderate_043_new.jpg', 'fabric_moderate_044_new.jpg', 'fabric_moderate_045_new.jpg', 'fabric_moderate_046_new.jpg', 'fabric_moderate_047_new.jpg', 'fabric_moderate_048_new.jpg', 'fabric_moderate_049_new.jpg', 'fabric_moderate_050_new.jpg', 'fabric_object_001_new.jpg', 'fabric_object_002_new.jpg', 'fabric_object_003_new.jpg', 'fabric_object_004_new.jpg', 'fabric_object_005_new.jpg', 'fabric_object_006_new.jpg', 'fabric_object_007_new.jpg', 'fabric_object_008_new.jpg', 'fabric_object_009_new.jpg', 'fabric_object_010_new.jpg', 'fabric_object_011_new.jpg', 'fabric_object_012_new.jpg', 'fabric_object_013_new.jpg', 'fabric_object_014_new.jpg', 'fabric_object_015_new.jpg', 'fabric_object_016_new.jpg', 'fabric_object_017_new.jpg', 'fabric_object_018_new.jpg', 'fabric_object_019_new.jpg', 'fabric_object_020_new.jpg', 'fabric_object_021_new.jpg', 'fabric_object_022_new.jpg', 'fabric_object_023_new.jpg', 'fabric_object_024_new.jpg', 'fabric_object_025_new.jpg', 'fabric_object_026_new.jpg', 'fabric_object_027_new.jpg', 'fabric_object_028_new.jpg', 'fabric_object_029_new.jpg', 'fabric_object_030_new.jpg', 'fabric_object_031_new.jpg', 'fabric_object_032_new.jpg', 'fabric_object_033_new.jpg', 'fabric_object_034_new.jpg', 'fabric_object_035_new.jpg', 'fabric_object_036_new.jpg', 'fabric_object_037_new.jpg', 'fabric_object_038_new.jpg', 'fabric_object_039_new.jpg', 'fabric_object_040_new.jpg', 'fabric_object_041_new.jpg', 'fabric_object_042_new.jpg', 'fabric_object_043_new.jpg', 'fabric_object_044_new.jpg', 'fabric_object_045_new.jpg', 'fabric_object_046_new.jpg', 'fabric_object_047_new.jpg', 'fabric_object_048_new.jpg', 'fabric_object_049_new.jpg', 'fabric_object_050_new.jpg']\n"
     ]
    }
   ],
   "source": [
    "m,n = 50,50\n",
    "#It lists all the files in a directory\n",
    "imgfiles=os.listdir('C:\\\\Users\\\\kumara213\\\\FMD\\\\input\\\\fabric');\n",
    "print (imgfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fabric\n",
      "glass\n",
      "leather\n",
      "metal\n",
      "paper\n",
      "plastic\n",
      "stone\n",
      "water\n",
      "wood\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\kumara213\\\\FMD\");\n",
    "\n",
    "path1=\"input\"\n",
    "path2=\"data\"\n",
    "\n",
    "classes=os.listdir(path2)\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for fol in classes:\n",
    "    print (fol)\n",
    "    imgfiles=os.listdir(path2+'\\\\'+fol);\n",
    "    for img in imgfiles: \n",
    "            im=Image.open(path2+'\\\\'+fol+'\\\\'+img)\n",
    "            im=im.convert(mode='RGB') \n",
    "            imrs=im.resize((m,n)) \n",
    "            imrs=img_to_array(imrs)/255; \n",
    "            imrs=imrs.transpose(2,0,1); \n",
    "            imrs=imrs.reshape(3,m,n); \n",
    "            x.append(imrs) \n",
    "            y.append(fol) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converitng it to numpy array\n",
    "x=np.array(x);\n",
    "y=np.array(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "nb_classes=len(classes)\n",
    "nb_epoch=20\n",
    "nb_filters=32\n",
    "nb_pool=2\n",
    "nb_conv=3\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "uniques, id_train=np.unique(y_train,return_inverse=True)\n",
    "Y_train=np_utils.to_categorical(id_train,nb_classes)\n",
    "\n",
    "uniques, id_test=np.unique(y_test,return_inverse=True)\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_test=np_utils.to_categorical(id_test,nb_classes)\n",
    "print (Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumara213\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(3, 50, 50..., padding=\"same\")`\n",
      "  \n",
      "C:\\Users\\kumara213\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv,border_mode='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'));\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv));\n",
    "model.add(Activation('relu'));\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)));\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Flatten());\n",
    "model.add(Dense(128));\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Dense(nb_classes));\n",
    "model.add(Activation('softmax'));\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumara213\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\models.py:826: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 180 samples\n",
      "Epoch 1/5\n",
      "720/720 [==============================] - 280s - loss: 2.2782 - acc: 0.1333 - val_loss: 2.1782 - val_acc: 0.1556\n",
      "Epoch 2/5\n",
      "720/720 [==============================] - 279s - loss: 2.1209 - acc: 0.2111 - val_loss: 2.1435 - val_acc: 0.1833\n",
      "Epoch 3/5\n",
      "720/720 [==============================] - 282s - loss: 1.9873 - acc: 0.2736 - val_loss: 2.1761 - val_acc: 0.1556\n",
      "Epoch 4/5\n",
      "720/720 [==============================] - 285s - loss: 1.8472 - acc: 0.3639 - val_loss: 2.2212 - val_acc: 0.2111\n",
      "Epoch 5/5\n",
      "720/720 [==============================] - 283s - loss: 1.6858 - acc: 0.4208 - val_loss: 2.1439 - val_acc: 0.2278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176912b7400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch=5;\n",
    "batch_size=5;\n",
    "model.fit(x_train,Y_train,batch_size=batch_size,nb_epoch=nb_epoch,verbose=1,validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fabric\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files=os.listdir(path1);\n",
    "img=files[0] \n",
    "print (img)\n",
    "im = Image.open(path1 + '\\\\'+img+\"\\\\fabric_moderate_001_new.jpg\");\n",
    "imrs = im.resize((m,n))\n",
    "imrs=img_to_array(imrs)/255;\n",
    "imrs=imrs.transpose(2,0,1);\n",
    "imrs=imrs.reshape(3,m,n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0945937   0.09244005  0.12359759  0.12022618  0.0786435   0.08016567\n",
      "   0.12880763  0.185684    0.09584168]]\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "x.append(imrs)\n",
    "x=np.array(x);\n",
    "predictions = model.predict(x)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
