{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF stands for \"Term Frequency, Inverse Document Frequency.\" It's a way to score the importance of words (or \"terms\") in a document based on how frequently they appear across multiple documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Therefore, common words like \"the\" and \"for,\" which appear in many documents, will be scaled down. Words that appear frequently in a single document will be scaled up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf(word, blob) computes \"term frequency\" which is the number of times a word appears in a document blob, normalized by dividing by the total number of words in blob. We use TextBlob for breaking up the text into words and getting the word counts.\n",
    "n_containing(word, bloblist) returns the number of documents containing word. A generator expression is passed to the sum() function.\n",
    "idf(word, bloblist) computes \"inverse document frequency\" which measures how common a word is among all documents in bloblist. The more common a word is, the lower its idf. We take the ratio of the total number of documents to the number of documents containing word, then take the log of that. Add 1 to the divisor to prevent division by zero.\n",
    "tfidf(word, blob, bloblist) computes the TF-IDF score. It's the product of tf and idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1------------------------------------->>>>>\n",
      "dict_items([('for', 0.0033234844926898722), ('two', 0.0033234844926898722), ('is', -0.0023580497741949257), ('film', 0.0066469689853797444), ('followed', 0.0033234844926898722), ('The', 0.0), ('Dana', 0.0033234844926898722), ('California', 0.0066469689853797444), ('girl', 0.0033234844926898722), ('role', 0.0033234844926898722), ('Robert', 0.0033234844926898722), ('Freddy', 0.0033234844926898722), ('genetically', 0.0033234844926898722), ('his', 0.0033234844926898722), ('including', 0.0033234844926898722), ('actors', 0.0033234844926898722), ('2004', 0.0033234844926898722), ('Clabaugh', 0.0033234844926898722), ('Zabka', 0.0033234844926898722), ('series', 0.0033234844926898722), ('small', 0.0033234844926898722), ('itself', 0.0033234844926898722), ('2002', 0.0033234844926898722), ('was', 0.0), ('Dien', 0.0033234844926898722), ('Barron', 0.0033234844926898722), ('Street', 0.0033234844926898722), ('python', 0.01661742246344936), ('sequels', 0.0033234844926898722), ('concerns', 0.0033234844926898722), ('that', 0.0033234844926898722), ('made-for-TV', 0.0066469689853797444), ('Wil', 0.0033234844926898722), ('the', -0.014148298645169552), ('on', 0.0066469689853797444), ('McCarthy', 0.0033234844926898722), ('II', 0.0033234844926898722), ('fame', 0.0033234844926898722), ('best', 0.0033234844926898722), ('Angeles', 0.0033234844926898722), ('Englund', 0.0033234844926898722), ('Kid', 0.0033234844926898722), ('movie', 0.0033234844926898722), ('in', -0.007074149322584776), ('directed', 0.0033234844926898722), ('13th', 0.0033234844926898722), ('Van', 0.0033234844926898722), ('by', 0.0), ('Friday', 0.0033234844926898722), ('cult', 0.0033234844926898722), ('vs', 0.0033234844926898722), ('films', 0.009970453478069616), ('escapes', 0.0033234844926898722), ('Boa', 0.0033234844926898722), ('Sean', 0.0033234844926898722), ('of', -0.004716099548389851), ('and', -0.009432199096779703), ('favorite', 0.0033234844926898722), ('includes', 0.0033234844926898722), ('Malibu', 0.0033234844926898722), ('It', 0.0), ('horror', 0.0033234844926898722), ('Keith', 0.0033234844926898722), ('evident', 0.0033234844926898722), ('town', 0.0033234844926898722), ('also', 0.0033234844926898722), ('both', 0.0033234844926898722), ('final', 0.0033234844926898722), ('David', 0.0033234844926898722), ('as', 0.0), ('several', 0.0033234844926898722), ('Wheaton', 0.0033234844926898722), ('unleashes', 0.0033234844926898722), ('Karate', 0.0033234844926898722), ('Whalen', 0.0033234844926898722), ('A', 0.0), ('classic', 0.0033234844926898722), ('like', 0.0033234844926898722), ('filmed', 0.0033234844926898722), ('William', 0.0033234844926898722), ('Coogan', 0.0033234844926898722), ('snake', 0.0033234844926898722), ('2000', 0.0033234844926898722), ('Jenny', 0.0033234844926898722), ('Python', -0.011790248870974625), ('Casper', 0.0033234844926898722), ('a', -0.011790248870974625), ('features', 0.0033234844926898722), ('Nightmare', 0.0033234844926898722), ('Krueger', 0.0033234844926898722), ('Los', 0.0033234844926898722), ('Elm', 0.0033234844926898722), ('scenario', 0.0033234844926898722), ('known', 0.0), ('Bowe', 0.0033234844926898722), ('engineered', 0.0033234844926898722), ('Richard', 0.0033234844926898722)])\n",
      "\tWord: python, TF-IDF: 0.01662\n",
      "\tWord: films, TF-IDF: 0.00997\n",
      "\tWord: film, TF-IDF: 0.00665\n",
      "Top words in document 2------------------------------------->>>>>\n",
      "dict_items([('in', -0.00777519114734543), ('and', -0.00777519114734543), ('longest', 0.010958516435355795), ('is', -0.01555038229469086), ('this', 0.010958516435355795), ('A', 0.0), ('pythons', 0.010958516435355795), ('known', 0.0), ('2', 0.02191703287071159), ('member', 0.010958516435355795), ('recognised', 0.010958516435355795), ('the', -0.01555038229469086), ('πύθων/πύθωνας', 0.010958516435355795), ('found', 0.010958516435355795), ('Currently', 0.010958516435355795), ('snakes', 0.010958516435355795), ('Python', -0.00777519114734543), ('of', -0.01555038229469086), ('Africa', 0.010958516435355795), ('Greek', 0.010958516435355795), ('among', 0.010958516435355795), ('word', 0.010958516435355795), ('P', 0.010958516435355795), ('nonvenomous', 0.010958516435355795), ('species', 0.010958516435355795), ('7', 0.010958516435355795), ('from', 0.010958516435355795), ('are', 0.010958516435355795), ('a', -0.01555038229469086), ('Asia', 0.010958516435355795), ('genus', 0.02191703287071159), ('reticulatus', 0.010958516435355795)])\n",
      "\tWord: 2, TF-IDF: 0.02192\n",
      "\tWord: genus, TF-IDF: 0.02192\n",
      "\tWord: longest, TF-IDF: 0.01096\n",
      "Top words in document 3------------------------------------->>>>>\n",
      "dict_items([('in', -0.003232382836536864), ('revolver', 0.013667363194657226), ('is', -0.006464765673073728), ('first', 0.0045557877315524084), ('Hartford', 0.0045557877315524084), ('V', 0.0045557877315524084), ('The', 0.0), ('357', 0.0045557877315524084), ('by', 0.0), ('finest', 0.0045557877315524084), ('year', 0.0045557877315524084), ('the', -0.019394297019221185), ('such', 0.0045557877315524084), ('Thompson', 0.0045557877315524084), ('was', 0.0), ('M29', 0.0045557877315524084), ('Jeff', 0.0045557877315524084), ('of', -0.003232382836536864), ('market', 0.0045557877315524084), ('Connecticut', 0.0045557877315524084), ('It', 0.0), ('Hogg', 0.0045557877315524084), ('collectors', 0.0045557877315524084), ('Hawks', 0.0045557877315524084), ('sometimes', 0.0045557877315524084), ('1', 0.0045557877315524084), ('Ian', 0.0045557877315524084), ('Martin', 0.0045557877315524084), ('introduced', 0.0045557877315524084), ('a', -0.006464765673073728), ('amp', 0.0045557877315524084), ('Dougherty', 0.0045557877315524084), ('discontinued', 0.0045557877315524084), ('as', 0.0), ('Renee', 0.0045557877315524084), ('Smeets', 0.0045557877315524084), ('Colt', 0.013667363194657226), ('and', -0.006464765673073728), ('same', 0.0045557877315524084), ('referred', 0.0045557877315524084), ('Smith', 0.0045557877315524084), ('Chuck', 0.0045557877315524084), ('to', 0.0045557877315524084), ('segment', 0.0045557877315524084), ('described', 0.0045557877315524084), ('Combat', 0.0045557877315524084), ('made', 0.0045557877315524084), ('caliber', 0.0045557877315524084), ('premium', 0.0045557877315524084), ('ever', 0.0045557877315524084), ('Magnum', 0.013667363194657226), ('production', 0.0045557877315524084), (\"'s\", 0.009111575463104817), ('Manufacturing', 0.0045557877315524084), ('Python', -0.009697148509610592), ('have', 0.0045557877315524084), ('manufactured', 0.0045557877315524084), ('firearm', 0.0045557877315524084), ('Wesson', 0.0045557877315524084), ('1955', 0.0045557877315524084), ('Cooper', 0.0045557877315524084), ('writers', 0.0045557877315524084), ('44', 0.0045557877315524084), ('formerly', 0.0045557877315524084), ('targeted', 0.0045557877315524084), ('Some', 0.0045557877315524084), ('Leroy', 0.0045557877315524084), ('now', 0.0045557877315524084), ('Company', 0.0045557877315524084)])\n",
      "\tWord: revolver, TF-IDF: 0.01367\n",
      "\tWord: Colt, TF-IDF: 0.01367\n",
      "\tWord: Magnum, TF-IDF: 0.01367\n"
     ]
    }
   ],
   "source": [
    "document1 = tb(\"\"\"Python is a 2000 made-for-TV horror movie directed by Richard\n",
    "Clabaugh. The film features several cult favorite actors, including William\n",
    "Zabka of The Karate Kid fame, Wil Wheaton, Casper Van Dien, Jenny McCarthy,\n",
    "Keith Coogan, Robert Englund (best known for his role as Freddy Krueger in the\n",
    "A Nightmare on Elm Street series of films), Dana Barron, David Bowe, and Sean\n",
    "Whalen. The film concerns a genetically engineered snake, a python, that\n",
    "escapes and unleashes itself on a small town. It includes the classic final\n",
    "girl scenario evident in films like Friday the 13th. It was filmed in Los Angeles,\n",
    " California and Malibu, California. Python was followed by two sequels: Python\n",
    " II (2002) and Boa vs. Python (2004), both also made-for-TV films.\"\"\")\n",
    "\n",
    "document2 = tb(\"\"\"Python, from the Greek word (πύθων/πύθωνας), is a genus of\n",
    "nonvenomous pythons[2] found in Africa and Asia. Currently, 7 species are\n",
    "recognised.[2] A member of this genus, P. reticulatus, is among the longest\n",
    "snakes known.\"\"\")\n",
    "\n",
    "document3 = tb(\"\"\"The Colt Python is a .357 Magnum caliber revolver formerly\n",
    "manufactured by Colt's Manufacturing Company of Hartford, Connecticut.\n",
    "It is sometimes referred to as a \"Combat Magnum\".[1] It was first introduced\n",
    "in 1955, the same year as Smith &amp; Wesson's M29 .44 Magnum. The now discontinued\n",
    "Colt Python targeted the premium revolver market segment. Some firearm\n",
    "collectors and writers such as Jeff Cooper, Ian V. Hogg, Chuck Hawks, Leroy\n",
    "Thompson, Renee Smeets and Martin Dougherty have described the Python as the\n",
    "finest production revolver ever made.\"\"\")\n",
    "\n",
    "bloblist = [document1, document2, document3]\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}------------------------------------->>>>>\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    print(scores.items())\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:3]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'awful': 21, 'boring': 16, 'and': 4, 'hate': 23, 'i': 10, 'awesome': 15, 'spaceship': 6, 'space': 26, '.': 0, 'a': 1, 'scenes': 19, 'alien': 20, 'liked': 11, ',': 13, 'action': 14, 'the': 7, 'characters': 18, 'but': 17, 'about': 2, 'please': 28, 'was': 8, '!': 9, 'films': 22, 'movie': 5, 'cool': 24, 'really': 12, 'more': 27, 'aliens': 3, 'is': 25}\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1)], [(5, 1), (7, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(0, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)], [(0, 1), (5, 1), (7, 1), (8, 1), (9, 1), (10, 1), (20, 1), (21, 1), (22, 1), (23, 1)], [(0, 1), (5, 1), (7, 1), (9, 1), (10, 1), (11, 1), (24, 1), (25, 1), (26, 1)], [(9, 1), (13, 1), (22, 1), (26, 1), (27, 1), (28, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Import Dictionary\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Create a Dictionary from the articles: dictionary\n",
    "#my_documents consists of list of \n",
    "my_documents = ['The movie was about a spaceship and The aliens.','I really liked the movie!','Awesome action scenes, but boring characters.',\n",
    "                'The movie was awful! I hate alien films.','Space is cool! I liked the movie.','More space films, please!',]\n",
    "\n",
    "articles=[word_tokenize(doc.lower()) for doc in my_documents]\n",
    "\n",
    "dictionary = Dictionary(articles)\n",
    "\n",
    "\n",
    "# Select the id for \"computer\": computer_id\n",
    "print(dictionary.token2id)\n",
    "\n",
    "# Create a MmCorpus: corpus\n",
    "corpus = [dictionary.doc2bow(article) for article in articles]\n",
    "\n",
    "# Print the first 10 word ids with their frequency counts from the fifth document\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->>>> . 1\n",
      "----->>>> movie 1\n",
      "----->>>> the 1\n",
      "----->>>> ! 1\n",
      "----->>>> i 1\n",
      "the 5\n",
      ". 4\n",
      "movie 4\n",
      "! 4\n",
      "i 3\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "from itertools import *\n",
    "\n",
    "# Save the fifth document: doc\n",
    "doc = corpus[4]\n",
    "\n",
    "# Sort the doc for frequency: bow_doc\n",
    "bow_doc = sorted(doc, key=lambda w: w[1], reverse=True)\n",
    "\n",
    "# Print the top 5 words of the document alongside the count\n",
    "for word_id, word_count in bow_doc[:5]:\n",
    "    print(\"----->>>>\",dictionary.get(word_id), word_count)\n",
    "    \n",
    "# Create the defaultdict: total_word_count\n",
    "total_word_count = defaultdict(int)\n",
    "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
    "    total_word_count[word_id] += word_count\n",
    "\n",
    "# Create a sorted list from the defaultdict: sorted_word_count \n",
    "sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True) \n",
    "\n",
    "# Print the top 5 words across all documents alongside the count\n",
    "for word_id, word_count in sorted_word_count[:5]:\n",
    "    print(dictionary.get(word_id), word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.12839429999391858), (5, 0.12839429999391858), (7, 0.12839429999391858), (9, 0.12839429999391858), (10, 0.21949150558476985)]\n",
      "cool 0.5673773111634582\n",
      "is 0.5673773111634582\n",
      "liked 0.3478858055786885\n",
      "space 0.3478858055786885\n",
      "i 0.21949150558476985\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfModel\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "# Create a new TfidfModel using the corpus: tfidf\n",
    "tfidf = TfidfModel(corpus)\n",
    "\n",
    "# Calculate the tfidf weights of doc: tfidf_weights\n",
    "tfidf_weights = tfidf[doc]\n",
    "\n",
    "# Print the first five weights\n",
    "print(tfidf_weights[:5])\n",
    "\n",
    "# Sort the weights from highest to lowest: sorted_tfidf_weights\n",
    "sorted_tfidf_weights = sorted(tfidf_weights, key=lambda w: w[1], reverse=True)\n",
    "\n",
    "# Print the top 5 weighted words\n",
    "for term_id, weight in sorted_tfidf_weights[:5]:\n",
    "    print(dictionary.get(term_id), weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
